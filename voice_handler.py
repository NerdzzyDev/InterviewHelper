# ‚Üí voice_handler.py
import base64
import io
import sounddevice as sd
import soundfile as sf
import numpy as np
import threading
from pynput import keyboard
import google.generativeai as genai
from config import API_KEY

genai.configure(api_key=API_KEY, transport='rest')

is_recording = False
audio_data = []
stream = None
alt_pressed = False

def get_default_microphone():
    device = sd.default.device[0]
    print(f"üé§ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {sd.query_devices(device)['name']}")
    return device

def start_recording():
    global is_recording, audio_data, stream
    if is_recording:
        return
    print("üî¥ –ó–∞–ø–∏—Å—å –Ω–∞—á–∞–ª–∞—Å—å (Alt+Z –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏)")
    audio_data = []
    is_recording = True

    def callback(indata, frames, time, status):
        if is_recording:
            audio_data.append(indata.copy())

    stream = sd.InputStream(device=get_default_microphone(), samplerate=44100, channels=1, dtype='float32', callback=callback)
    stream.start()
    threading.Timer(10.0, stop_recording).start()

def stop_recording():
    global is_recording, stream
    if not is_recording:
        return
    is_recording = False
    if stream:
        stream.stop()
        stream.close()
    if audio_data:
        full_audio = np.concatenate(audio_data)
        audio_buffer = io.BytesIO()
        sf.write(audio_buffer, full_audio, 44100, format="WAV")
        transcribe_audio(audio_buffer.getvalue())
    else:
        print("‚ùå –ù–µ—Ç –∑–≤—É–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

def transcribe_audio(audio_bytes):
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')
        audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
        response = model.generate_content([
            "–≠—Ç–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ Python. –û–ø—Ä–µ–¥–µ–ª–∏ –≤–æ–ø—Ä–æ—Å, –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –∏ –æ–±—ä—è—Å–Ω–∏:",
            {"mime_type": "audio/wav", "data": audio_base64}
        ], stream=False) # –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ True

        print("\nüîä –û—Ç–≤–µ—Ç –æ—Ç Gemini:")
        for chunk in response:
            if hasattr(chunk, 'text') and chunk.text:
                print(chunk.text)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

def on_press(key):
    global alt_pressed
    if key in {keyboard.Key.alt, keyboard.Key.alt_l, keyboard.Key.alt_r}:
        alt_pressed = True
    if hasattr(key, 'char') and key.char == 'z' and alt_pressed:
        if is_recording:
            stop_recording()
        else:
            start_recording()

def on_release(key):
    global alt_pressed
    if key in {keyboard.Key.alt, keyboard.Key.alt_l, keyboard.Key.alt_r}:
        alt_pressed = False

def run_voice_assistant():
    print("üéôÔ∏è –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∑–∞–ø—É—â–µ–Ω. Alt+Z –¥–ª—è –∑–∞–ø–∏—Å–∏")
    with keyboard.Listener(on_press=on_press, on_release=on_release) as listener:
        listener.join()
